{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx # the main libary we will use\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit \n",
    "from itertools import combinations\n",
    "from nxviz.plots import CircosPlot\n",
    "from nxviz import ArcPlot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import dask\n",
    "import dask.array as da, dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bipartite Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(users, movies, df):\n",
    "    B = nx.Graph()\n",
    "\n",
    "    # Add nodes with the node attribute \"bipartite\"\n",
    "    B.add_nodes_from(users, bipartite=0)\n",
    "    B.add_nodes_from(movies, bipartite=1)\n",
    "\n",
    "    # Add edges only between nodes of opposite node sets\n",
    "    B.add_weighted_edges_from(df[\"edge\"].values.tolist(), weight=\"rating\")\n",
    "\n",
    "    #check that the node set is actually correct and that the input graph is actually bipartite.\n",
    "    print(nx.is_connected(B))\n",
    "    print(nx.is_bipartite(B))\n",
    "    print ('Number of nodes: {}'.format(B.number_of_nodes()))\n",
    "    print ('Number of edges: {}'.format(B.number_of_edges()))\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project one side of the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_side(B,type_v, def_group):\n",
    "    G_movies = bipartite.weighted_projected_graph(B, type_v, ratio=True)\n",
    "    attributes_dictionary = def_group.to_dict('index')\n",
    "    nx.set_node_attributes(G_movies, attributes_dictionary)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_g(G):\n",
    "    nx.draw(G, pos=nx.spring_layout(G_movies), with_labels = True, node_color = \"#00CCFF\")\n",
    "    plt.show()\n",
    "\n",
    "def CircosPlot(G, grouping):\n",
    "    c = CircosPlot(\n",
    "        G,\n",
    "        dpi=600,\n",
    "        node_grouping=grouping,\n",
    "        edge_width=\"count\",\n",
    "        figsize=(20, 20),\n",
    "        node_color=grouping,\n",
    "        node_labels=True,\n",
    "    )\n",
    "    c.draw()\n",
    "    plt.show()\n",
    "\n",
    "def ArcPlot(G, grouping):\n",
    "    a = ArcPlot(G, node_color=grouping, node_grouping=grouping)\n",
    "    a.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_degree_dist(G):\n",
    "    degree_hist = nx.degree_histogram(G) \n",
    "    print (degree_hist)\n",
    "    degree_hist = np.array(degree_hist, dtype=float)\n",
    "    degree_prob = degree_hist/G.number_of_nodes()\n",
    "    # plotting\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    axes = fig.add_axes([1,1,1,1])\n",
    "    \n",
    "    axes.loglog(np.arange(degree_prob.shape[0]), degree_prob, 'b.', markersize=15, alpha=0.5)\n",
    "    \n",
    "    axes.set_xlabel('k')\n",
    "    axes.set_ylabel('p(k)')\n",
    "    axes.set_title('Degree Distribution')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot knn as function of k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit function of the form:  $a\\cdot X^{\\mu}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_func(x,a,mu):\n",
    "    return (a*x)**mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_knn(G, fit=True): \n",
    "    knn_dict = nx.k_nearest_neighbors(G) # k_nearest_neighbors return dict with knn for each k\n",
    "    k_lst = sorted(knn_dict.keys())\n",
    "    knn_lst = []\n",
    "    for k in k_lst:\n",
    "        knn_lst.append(knn_dict[k])\n",
    "    \n",
    "    # plotting\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    axes = fig.add_axes([1,1,1,1])\n",
    "    \n",
    "    axes.loglog(k_lst,knn_lst,'b.', markersize=15, alpha=0.5)\n",
    "    \n",
    "    axes.set_xlabel('k')\n",
    "    axes.set_ylabel('knn(k)')\n",
    "    axes.set_title('Average next neighbor degree')\n",
    "    try:\n",
    "        if fit:\n",
    "            # fit a*x^mu\n",
    "            popt, pcov = curve_fit(fit_func, np.array(k_lst), np.array(knn_lst))\n",
    "            axes.loglog(np.array(k_lst), fit_func(np.array(k_lst), *popt), '--', c='gray')\n",
    "\n",
    "        plt.show()\n",
    "    except:\n",
    "        print (\"RuntimeError: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot snn as function of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_snn(G, fit=True): \n",
    "    snn_dict = nx.k_nearest_neighbors(G, weight='weight') \n",
    "    k_lst = sorted(snn_dict.keys())\n",
    "    snn_lst = []\n",
    "    for k in k_lst:\n",
    "        snn_lst.append(snn_dict[k])\n",
    "    \n",
    "    # plotting\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    axes = fig.add_axes([1,1,1,1])\n",
    "    \n",
    "    axes.loglog(k_lst,snn_lst,'b.', markersize=15, alpha=0.5)\n",
    "    \n",
    "    axes.set_xlabel('k')\n",
    "    axes.set_ylabel('snn(k)')\n",
    "    axes.set_title('Average next neighbor strength')\n",
    "    try:\n",
    "        if fit:\n",
    "            # fit a*x^mu\n",
    "            popt, pcov = curve_fit(fit_func, np.array(k_lst), np.array(snn_lst))\n",
    "            axes.loglog(np.array(k_lst), fit_func(np.array(k_lst), *popt), '--', c='gray')\n",
    "\n",
    "        plt.show()\n",
    "    except:\n",
    "        print (\"RuntimeError: Optimal parameters not found: Number of calls to function has reached maxfev = 600.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering coefficient for k\n",
    "calculate C(k) the average clustering coefficient for nodes with degree k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering_coefficient(G):\n",
    "    clustering_dict = {}\n",
    "    for node in G.nodes():\n",
    "        k = G.degree(node)\n",
    "        if not k in clustering_dict:\n",
    "            clustering_dict[k] = [nx.clustering(G,node)]\n",
    "        else:\n",
    "            clustering_dict[k].append(nx.clustering(G,node))\n",
    "    k_lst = sorted(clustering_dict.keys())\n",
    "    clustering_lst = []\n",
    "    for k in k_lst:\n",
    "        clustering_lst.append(np.array(clustering_dict[k]).mean())\n",
    "    \n",
    "    # plotting\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    axes = fig.add_axes([1,1,1,1])\n",
    "    \n",
    "    axes.loglog(k_lst,clustering_lst,'b.', markersize=15, alpha=0.5)\n",
    "    \n",
    "    axes.set_xlabel('k')\n",
    "    axes.set_ylabel('C(k)')\n",
    "    axes.set_title('Average clustering coefficient')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_attributes(G):\n",
    "# Diameter, Connected, Degree Assortativity Coefficient\n",
    "    dict_data = {}\n",
    "    info = nx.info(G)\n",
    "    print (info)\n",
    "    splited = info.splitlines()\n",
    "    for s in splited:\n",
    "        split = s.strip().split(\":\")\n",
    "        dict_data[split[0]]=split[1]       \n",
    "    dac = nx.degree_assortativity_coefficient(G)\n",
    "    print ('Degree Assortativity Coefficient (r): %s' % dac)\n",
    "    if not nx.is_directed(G):\n",
    "        if nx.is_connected(G):\n",
    "            diameter = nx.diameter(G)\n",
    "            print ('Diameter: %s' % diameter) # print diameter of the network\n",
    "            dict_data[\"Diameter\"] = diameter\n",
    "            return dict_data\n",
    "        else:\n",
    "            print ('Graph not connected: infinite path length')\n",
    "            large_comp = len(max(nx.connected_components(G), key=len))\n",
    "            print ('Size of largest component: %s' % large_comp)\n",
    "            dict_data[\"largest component\"] = large_comp\n",
    "            return dict_data\n",
    "    \n",
    "\n",
    "def plot_hist(list_to_plot,x_label):\n",
    "    plt.hist(list_to_plot)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.show()\n",
    "        \n",
    "def calculate_degree(G):\n",
    "    d = dict(G.degree(G.nodes()))\n",
    "    nx.set_node_attributes(G, d, 'degree')\n",
    "    df_degree = pd.DataFrame.from_dict(d, orient='index', columns=['degree']).sort_values(by='degree', ascending=False)\n",
    "    \n",
    "    #plot_degree\n",
    "    #plot_hist(d.values(),'degree')\n",
    "    \n",
    "    return G, df_degree\n",
    "    \n",
    "def calculate_degree_centrality(G):\n",
    "    print (\"\\nCalculating Degree Centrality...\")\n",
    "    dc = nx.degree_centrality(G)\n",
    "    nx.set_node_attributes(G, dc, 'degree_cent')\n",
    "    df_degree_centrality = pd.DataFrame.from_dict(dc, orient='index', columns=['degree_centrality']).sort_values(by='degree_centrality', ascending=False)\n",
    "    \n",
    "    #plot_degree_centrality\n",
    "    #plot_hist(dc.values(),'degree_centrality')\n",
    "    \n",
    "    return G, df_degree_centrality\n",
    "\n",
    "## Finding Major Movies (PageRank)\n",
    "#identify the key or most “important” entities in the graph. \n",
    "#To do this, we will run the PageRank algorithm on top of the graph. This will assign a score to each node based on the structure of the incoming edges.\n",
    "\n",
    "def page_rank(G):    \n",
    "    # run PageRank on the graph. algorithm returns a dictionary with the scores\n",
    "    page_rank_dict = nx.pagerank(G)\n",
    "    nx.set_node_attributes(G, page_rank_dict, 'page rank')\n",
    "    df_page_rank = pd.DataFrame.from_dict(page_rank_dict, orient='index', columns=['Page Rank']).sort_values(by='Page Rank', ascending=False)\n",
    "    \n",
    "    #plot_page_rank\n",
    "    #plot_hist(page_rank_dict.values(),'page rank')\n",
    "    return G, df_page_rank\n",
    "    #print 'Max Pagerank player is {}:{}, Score:{}'.format(max_node_p,G.node[max_node_p]['title'],max_score)\n",
    "    \n",
    "def clustering_coefficient(G):\n",
    "    clustering = nx.clustering(G)\n",
    "    nx.set_node_attributes(G, clustering, 'clustering coefficient')\n",
    "    df_clustering_coefficient = pd.DataFrame.from_dict(clustering, orient='index', columns=['clustering coefficient']) # get clustering coefficient of all nodes\n",
    "    print (\"average clustering coefficient\"+ str(nx.average_clustering(G))) # get average clustering coefficient\n",
    "    \n",
    "    #plot_clustering_coefficient\n",
    "    #plot_hist(clustering.values(),'clustering coefficient')\n",
    "    return G, df_clustering_coefficient\n",
    "\n",
    "def calculate_eigenvector_centrality(graph):\n",
    "    print (\"\\n\\tCalculating Eigenvector Centrality...\")\n",
    "    g = graph\n",
    "    #ec = nx.eigenvector_centrality_numpy(g)\n",
    "    #nx.set_node_attributes(g, 'eigenvector', ec)\n",
    "    eigenvector_dict = nx.eigenvector_centrality(G) # Run eigenvector centrality\n",
    "    nx.set_node_attributes(G, eigenvector_dict, 'eigenvector')\n",
    "    df_eigenvector = pd.DataFrame.from_dict(eigenvector_dict, orient='index', columns=['eigenvector']).sort_values(by='eigenvector', ascending=False)\n",
    "    \n",
    "    #plot_eigenvector\n",
    "    #plot_hist(eigenvector_dict.values(),'eigenvector')\n",
    "    plt.show()\n",
    "    \n",
    "    return G, df_eigenvector\n",
    "\n",
    "## Betweenness Centrality\n",
    "#finding the key intermediary nodes in terms of how information may flow inside the graph.\n",
    "#Vertices with high betweenness centrality, means that they have a large influence in the connectivity of their neighbors with the other nodes in the graph.\n",
    "\n",
    "def betweennes(G):    \n",
    "    betweenness_dict = nx.betweenness_centrality(G)\n",
    "    nx.set_node_attributes(G, betweenness_dict, 'betweenness')\n",
    "    df_betweeness_rank = pd.DataFrame.from_dict(betweenness_dict, orient='index', columns=['betweennes']).sort_values(by='betweennes', ascending=False)\n",
    "    \n",
    "    #plot_betweennes\n",
    "    #plot_hist(betweenness_dict.values(),'betweenness')\n",
    "    \n",
    "    return G, df_betweeness_rank\n",
    "    #print 'Max betweenness_centrality player is {}:{}, Score:{}'.format(max_node_b,G.node[max_node_b]['name'],max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parameters(top_df, sort_column, column_by ,title):\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(10, 8), dpi=600)\n",
    "    \n",
    "    #sns.barplot(x=column_by, y=\"value\", data=top_df, hue=\"parameter\", palette='winter_r', orient='v')\n",
    "    sns.catplot(x=\"value\", y=column_by, data=top_df, hue=\"parameter\", palette='winter_r', kind='bar', orient='h')\n",
    "    # \"Top 10 Authors, normalized parameters\"\n",
    "    plt.tight_layout()\n",
    "    plt.title(title)\n",
    "    plt.legend(bbox_to_anchor=(0, 1), loc='upper left', ncol=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Nodes with highest parameter value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find nodes with highest score\n",
    "def find_nodes_with_highest_score(df, score):\n",
    "    max_score = df[score].max()\n",
    "    df_max_nodes = df[df[score]==max_score]\n",
    "    return df_max_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluester similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_best_partition(G):\n",
    "    communities = community.best_partition(G)\n",
    "    nx.set_node_attributes(G, communities, 'modularity')\n",
    "    return G\n",
    "\n",
    "def community_kernighan_lin_bisection(G):\n",
    "    KL_communities_generator = community.kernighan_lin_bisection(G,max_iter=10)\n",
    "    for s in KL_communities_generator:\n",
    "        print (s)\n",
    "        \n",
    "def community_girvan_newman(G):  \n",
    "    GN_communities_generator = community.girvan_newman(G)\n",
    "    top_level_communities = next(GN_communities_generator)\n",
    "    next_level_communities = next(GN_communities_generator)\n",
    "    GN_comm_sets = sorted(map(sorted, next_level_communities))\n",
    "\n",
    "def modularity(G,communites):\n",
    "    return community.modularity(G,communites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friend Recommendation: Open Triangles\n",
    "we want to see if we can do some friend recommendations by looking for open triangles.\n",
    "Open triangles are - A knows B and B knows C, but C's relationship with A isn't captured in the graph.\n",
    "What are the two general scenarios for finding open triangles that a given node is involved in?\n",
    "The given node is the centre node.\n",
    "The given node is one of the termini nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_open_triangles(G, node):\n",
    "    open_triangle_nodes = []\n",
    "    neighbors = set(G.neighbors(node))\n",
    "    \n",
    "    for n1, n2 in combinations(neighbors, 2):\n",
    "        if not G.has_edge(n1, n2):\n",
    "            open_triangle_nodes.append([n1, node, n2])\n",
    "            frieds_pair_recomded.append((n1, n2))\n",
    "    preds = nx.jaccard_coefficient(G, frieds_pair_recomded)\n",
    "#     for u, v, p in preds:\n",
    "#         '(%d, %d) -> %.8f' % (u, v, p)\n",
    "    df = pd.DataFrame(list(preds),columns=['n1','n2','jaccard']).sort_values(by=['n1','n2','jaccard'])\n",
    "    max_jaccard_by_user = df.groupby('n')['jaccard'].max().reset_index(name='max')\n",
    "    return open_triangle_nodes, max_jaccard_by_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find shared movies: Transposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_user_projection_matrix(G):\n",
    "    #compute adjacency matrix\n",
    "    # Get the list of people and list of clubs from the graph: users_nodes, movies_nodes\n",
    "    users_nodes = get_nodes_from_partition(G, 'users')\n",
    "    movies_nodes = get_nodes_from_partition(G, 'movies')\n",
    "\n",
    "    # Compute the biadjacency matrix: bi_matrix\n",
    "    bi_matrix = nx.bipartite.biadjacency_matrix(G, row_order=users_nodes, column_order=movies_nodes)\n",
    "\n",
    "    # Compute the user-user projection: user_matrix\n",
    "    user_matrix = bi_matrix @ bi_matrix.T\n",
    "\n",
    "    return users_nodes, user_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharing(user_matrix, user_nodes):\n",
    "    # Find out the users who rated the most number of movies\n",
    "    diag = user_matrix.diagonal() \n",
    "    indices = np.where(diag == diag.max())[0]  \n",
    "    print('Number of movies: {0}'.format(diag.max()))\n",
    "    print('Users with the most # rating:')\n",
    "    for i in indices:\n",
    "        print('- {0}'.format(user_nodes[i]))\n",
    "\n",
    "    # Set the diagonal to zero and convert it to a coordinate matrix format\n",
    "    user_matrix.setdiag(0)\n",
    "    users_coo = user_matrix.tocoo()\n",
    "\n",
    "    # Find pairs of users who shared rating in the most number of movies\n",
    "    indices = np.where(users_coo.data == users_coo.data.max())[0]\n",
    "    print('Users with most shared movies:')\n",
    "    for idx in indices:\n",
    "        print('- {0}, {1}'.format(user_nodes[users_coo.row[idx]], user_nodes[users_coo.col[idx]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph differences over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_difference(Gs):\n",
    "    # Instantiate a list of graphs that show edges added: added\n",
    "    added = []\n",
    "    # Instantiate a list of graphs that show edges removed: removed\n",
    "    removed = []\n",
    "    # Here's the fractional change over time\n",
    "    fractional_changes = []\n",
    "    window = 1  \n",
    "    i = 0      \n",
    "\n",
    "    for i in range(len(Gs) - window):\n",
    "        g1 = Gs[i]\n",
    "        g2 = Gs[i + window]\n",
    "\n",
    "        # Compute graph difference here\n",
    "        added.append(nx.difference(g2, g1))   \n",
    "        removed.append(nx.difference(g1, g2))\n",
    "\n",
    "        # Compute change in graph size over time\n",
    "        fractional_changes.append((len(g2.edges()) - len(g1.edges())) / len(g1.edges()))\n",
    "\n",
    "    # Print the fractional change\n",
    "    print(fractional_changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot number of edge changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diffrences(added, removed, fractional_changes):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "\n",
    "    # Plot the number of edges added over time\n",
    "    edges_added = [len(g.edges()) for g in added]\n",
    "    plot1 = ax1.plot(edges_added, label='added', color='orange')\n",
    "\n",
    "    # Plot the number of edges removed over time\n",
    "    edges_removed = [len(g.edges()) for g in removed]\n",
    "    plot2 = ax1.plot(edges_removed, label='removed', color='purple')\n",
    "\n",
    "    # Set yscale to logarithmic scale\n",
    "    ax1.set_yscale('log')  \n",
    "    ax1.legend()\n",
    "\n",
    "    # 2nd axes shares x-axis with 1st axes object\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Plot the fractional changes over time\n",
    "    plot3 = ax2.plot(fractional_changes, label='fractional change', color='green')\n",
    "\n",
    "    # Here, we create a single legend for both plots\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines1 + lines2, labels1 + labels2, loc=0)\n",
    "    plt.axhline(0, color='green', linestyle='--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot number of edges over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_edges_over_time(edge_sizes, year):    \n",
    "    fig = plt.figure()\n",
    "    # Plot edge sizes over time\n",
    "    plt.plot(edge_sizes)\n",
    "    plt.xlabel('Time elapsed from year %s.'% str(year)) \n",
    "    plt.ylabel('Number of edges')                           \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# degree centrality over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_time(cents,start,end):\n",
    "    # Plot ECDFs over time\n",
    "    fig = plt.figure()\n",
    "    for i in range(start,end+1):\n",
    "        x, y = ECDF(cents[i].values()) \n",
    "        plt.plot(x, y, label='Year {0}'.format()) \n",
    "    plt.legend()   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data and add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r\"sample_100k (1).csv\"\n",
    "path = r\"Data/25k_users_sample.csv\"\n",
    "#path = r\"final_100k_users_sample.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df_movies = pd.read_csv(r\"Data/movie_titles.csv\", names=[\"year\",\"title\"], index_col=0, encoding=\"ISO-8859-1\",parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"movie\"] = df[\"movie\"].astype(str)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df_movies.fillna(0,inplace=True)\n",
    "df_movies[\"year\"] = df_movies[\"year\"].astype(\"int64\")\n",
    "df_movies[\"movie\"] = df_movies.index\n",
    "df = df.merge(df_movies, on=\"movie\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.from_pandas(df, npartitions=2*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\or\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\core.py:3152: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={0: 'int64', 1: 'int64', 2: 'int64', 3: 'int64'})\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    }
   ],
   "source": [
    "df = dd.from_pandas(df, npartitions=2*4)\n",
    "df[['week_day', 'year_rating', 'month', 'day_month']] = df.apply(dateTime_to_dat_year_month_date_time, axis=1, result_type='expand')\n",
    "df = df.compute()\n",
    "df[\"edge\"] = df.apply(create_edge,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\or\\Documents\\final_25k_users_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desribe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>movie</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>week_day</th>\n",
       "      <th>year_rating</th>\n",
       "      <th>month</th>\n",
       "      <th>day_month</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2625420</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-05-25</td>\n",
       "      <td>13368</td>\n",
       "      <td>1999</td>\n",
       "      <td>Sarfarosh</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>(2625420, 13368, 2.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1650301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2005-08-30</td>\n",
       "      <td>13368</td>\n",
       "      <td>1999</td>\n",
       "      <td>Sarfarosh</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>(1650301, 13368, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500511</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2003-08-11</td>\n",
       "      <td>13368</td>\n",
       "      <td>1999</td>\n",
       "      <td>Sarfarosh</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>(2500511, 13368, 4.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2473764</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-09-26</td>\n",
       "      <td>13368</td>\n",
       "      <td>1999</td>\n",
       "      <td>Sarfarosh</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>(2473764, 13368, 4.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>310049</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-03-15</td>\n",
       "      <td>13368</td>\n",
       "      <td>1999</td>\n",
       "      <td>Sarfarosh</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>(310049, 13368, 2.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  rating       date  movie  year      title  week_day  year_rating  \\\n",
       "0  2625420     2.0 2004-05-25  13368  1999  Sarfarosh         1         2004   \n",
       "1  1650301     1.0 2005-08-30  13368  1999  Sarfarosh         1         2005   \n",
       "2  2500511     4.0 2003-08-11  13368  1999  Sarfarosh         0         2003   \n",
       "3  2473764     4.0 2005-09-26  13368  1999  Sarfarosh         0         2005   \n",
       "4   310049     2.0 2004-03-15  13368  1999  Sarfarosh         0         2004   \n",
       "\n",
       "   month  day_month                   edge  \n",
       "0      5         25  (2625420, 13368, 2.0)  \n",
       "1      8         30  (1650301, 13368, 1.0)  \n",
       "2      8         11  (2500511, 13368, 4.0)  \n",
       "3      9         26  (2473764, 13368, 4.0)  \n",
       "4      3         15   (310049, 13368, 2.0)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a bipartite graph, nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"Data\\final_25k_users_sample.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\or\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(path,index_col=0)\n",
    "data[\"movie\"] = data[\"movie\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_str_to_tuple(val):\n",
    "    tup = list(val[1:-1].split(\",\"))\n",
    "    tup[0] = int(tup[0])\n",
    "    tup[1] = str(tup[1]).replace(\"'\",\"\").strip()\n",
    "    tup[2] = float(tup[2])\n",
    "    return tuple(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['edge'] = data['edge'].apply(transform_str_to_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_per_year = [x for _, x in data.groupby(data['year_rating'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_per_year_above2002 = df_list_per_year[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n",
      "True\n",
      "True\n",
      "Number of nodes: 11809\n",
      "Number of edges: 429321\n",
      "2004\n",
      "True\n",
      "True\n",
      "Number of nodes: 20808\n",
      "Number of edges: 1261715\n",
      "2005\n",
      "True\n",
      "True\n",
      "Number of nodes: 28420\n",
      "Number of edges: 1764376\n"
     ]
    }
   ],
   "source": [
    "list_B = []\n",
    "list_Gmovies = []\n",
    "for data in df_list_per_year_above2002:\n",
    "    print (data[\"year_rating\"].unique().tolist()[0])\n",
    "    users = data[\"user\"].unique().tolist()\n",
    "    movies = data[\"movie\"].unique().tolist()\n",
    "    # coumt/mean rating for each movie and count/mean rating for each user\n",
    "    df_per_movie = data.groupby([\"movie\",\"title\",\"year\"]).agg({'rating':\"mean\", 'user':'count'}).reset_index().rename(columns={'rating':'mean_rating','user' : '#rating'}).sort_values(by='#rating').reset_index(drop=True)\n",
    "    df_per_user = data.groupby([\"user\"]).agg({'rating':\"mean\", 'movie':'count'}).reset_index().rename(columns={'rating':'mean_rating','movie' : '#rating'}).sort_values(by='#rating').reset_index(drop=True)\n",
    "    \n",
    "    B = create_graph(users, movies, data)\n",
    "    G_users = project_side(B, movies, df_per_movie)\n",
    "    list_B.append(B)\n",
    "    list_Gmovies.append(G_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_graph(df.user, movies, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 11809\n",
      "Number of edges: 429321\n",
      "Average degree:  72.7108\n"
     ]
    }
   ],
   "source": [
    "d = print_attributes(list_Gmovies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 11809\n",
      "Number of edges: 429321\n",
      "Average degree:  72.7108\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-c71eb4b24f26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mG_movies\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_Gmovies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_movies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-a64ea71bfbe1>\u001b[0m in \u001b[0;36mprint_attributes\u001b[1;34m(G)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_directed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_connected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Diameter: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# print diameter of the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Graph not connected: infinite path length'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\distance_measures.py\u001b[0m in \u001b[0;36mdiameter\u001b[1;34m(G, e, usebounds)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mextrema_bounding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"diameter\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meccentricity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\distance_measures.py\u001b[0m in \u001b[0;36meccentricity\u001b[1;34m(G, v, sp)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnbunch_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetworkx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle_source_shortest_path_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.py\u001b[0m in \u001b[0;36msingle_source_shortest_path_length\u001b[1;34m(G, source, cutoff)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mcutoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mnextlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_single_shortest_path_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnextlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.py\u001b[0m in \u001b[0;36m_single_shortest_path_length\u001b[1;34m(adj, firstlevel, cutoff)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mseen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlevel\u001b[0m  \u001b[1;31m# set the level of vertex v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                 \u001b[0mnextlevel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# add neighbors of v\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\networkx\\classes\\coreviews.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_atlas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_atlas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for G_movies in list_Gmovies:\n",
    "    print_attributes(G_movies)\n",
    "    edge_sizes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_dist(G_movies)\n",
    "plot_snn(G_movies, fit=True)\n",
    "plot_knn(G_movies, fit=True)\n",
    "if not nx.is_directed(G):\n",
    "    plot_clustering_coefficient(G_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of degree centrality scores year-by-year\n",
    "cents = []\n",
    "G, df_degree = calculate_degree(G_movies)\n",
    "G, df_degree_centrality = calculate_degree_centrality(G)\n",
    "G, df_page_rank = page_rank(G)\n",
    "G, df_clustering = clustering_coefficient(G)\n",
    "G, df_eigenvector = calculate_eigenvector_centrality(G)\n",
    "G, df_betweeness_rank = betweennes(G)\n",
    "dfs = [df_degree, df_degree_centrality, df_page_rank, df_clustering, df_eigenvector, df_betweeness_rank]\n",
    "df_final = reduce(lambda left,right: pd.merge(left, right,on='name'), dfs)\n",
    "\n",
    "nx.write_gexf(G, \"movies_25_graph.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot scatter of degree vs. degree_centrality\n",
    "plt.scatter(x=df_degree['degree'], y=df_degree_centrality['degree_centrality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.merge(df_per_movie, left_index=True, right_index=True)\n",
    "df_final.to_csv(\"graph_calculation.csv\")\n",
    "df_final.drop(['year', 'movie'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Top 10 normalized parameters\"\n",
    "for col in df_final.columns:\n",
    "    if col!='title':\n",
    "        df_final[col] = df_final[col] / max(df_final[col])\n",
    "df_final.set_index('title',inplace=True)\n",
    "\n",
    "top_df = df_final.sort_values('mean_rating', ascending=False)[:10]\n",
    "top_df = pd.DataFrame(top_df.stack()).reset_index()\n",
    "top_df.columns = ['title', \"parameter\", \"value\"]\n",
    "#top_df.set_index('title',inplace=True)\n",
    "top_df['title'] = top_df['title'].astype(\"category\") \n",
    "top_df['value'] = top_df['value'].apply(pd.to_numeric)\n",
    "plot_parameters(top_df, 'mean_rating', 'title', title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.hist(bins=15,figsize=(10,10), density=True, align='mid',log =True,grid =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = community_best_partition(G)\n",
    "#plotting the communities\n",
    "plot_g(G)\n",
    "CircosPlot(G, 'communities')\n",
    "ArcPlot(G, 'communities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_open_triangles(G, node)\n",
    "users_nodes, user_matrix = user_user_projection_matrix(G)  \n",
    "sharing(user_matrix, user_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
